{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8999acb",
   "metadata": {},
   "source": [
    "## gemini API CHAT 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d9a3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api 발급 받아서 .env에 저장\n",
    "# Key 로딩해서 출력하기\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 OPENAIAPI 환경 변수 로드\n",
    "#load_dotenv(\"../,env\", override=True) # 경로설정시\n",
    "load_dotenv(override=True)\n",
    "api = os.getenv(\"GEMINIAPI\")\n",
    "# print(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d51b5",
   "metadata": {},
   "source": [
    "# 기본 CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6142a4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='AI learns patterns from data to make predictions or decisions.\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.08905194203058879, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=12, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=12)], prompt_token_count=8, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=8)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=20, traffic_type=None) automatic_function_calling_history=[] parsed=None\n",
      "AI learns patterns from data to make predictions or decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=api)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "# 결과 출력\n",
    "print(response)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23188f",
   "metadata": {},
   "source": [
    "# 이미지 편집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47adce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제공된 이미지의 보디빌더가 다양한 운동기구가 배치된 활기찬 헬스장 환경에 있는 모습을 묘사하겠습니다. 밝은 조명 아래, 땀방울이 살짝 맺힌 근육질의 남성이 운동 전 집중하는 모습으로 서 있는 구도로 이미지를 생성합니다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import PIL.Image\n",
    "\n",
    "try:\n",
    "  image = Image.open(\"bodybuilder.png\")\n",
    "except FileNotFoundError:\n",
    "  print(\"오류: 이미지 파일을 찾을 수 없습니다.\")\n",
    "  exit()\n",
    "client = genai.Client(api_key=api)\n",
    "\n",
    "text_input = ('헬스장으로 배경을 바꿔줘')\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-preview-image-generation\",\n",
    "    contents=[text_input, image],\n",
    "    config=types.GenerateContentConfig(\n",
    "      response_modalities=['TEXT', 'IMAGE']\n",
    "    )\n",
    ")\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "  if part.text is not None:\n",
    "    print(part.text)\n",
    "  elif part.inline_data is not None:\n",
    "    image = Image.open(BytesIO(part.inline_data.data))\n",
    "\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7131772b",
   "metadata": {},
   "source": [
    "# 동영상(유튜브)콘텐츠 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a6e2d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Sure! Here is a 3-sentence summary of the video:\\nThe video is a demo of multimodal live streaming in Gemini 2.0. A tab with a document is cast into AI studio, and the AI is asked to read the highlighted text and to define the word “multimodal.” The AI is also asked to tell a story, which the user interrupts, and then to summarize everything seen and heard so far.')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.5900156744595232, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=87, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=87)], prompt_token_count=42474, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=9), ModalityTokenCount(modality=<MediaModality.AUDIO: 'AUDIO'>, token_count=3725), ModalityTokenCount(modality=<MediaModality.VIDEO: 'VIDEO'>, token_count=38740)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=42561, traffic_type=None) automatic_function_calling_history=[] parsed=None\n",
      "Sure! Here is a 3-sentence summary of the video:\n",
      "The video is a demo of multimodal live streaming in Gemini 2.0. A tab with a document is cast into AI studio, and the AI is asked to read the highlighted text and to define the word “multimodal.” The AI is also asked to tell a story, which the user interrupts, and then to summarize everything seen and heard so far.\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model='models/gemini-2.0-flash',\n",
    "    contents=types.Content(\n",
    "        parts=[\n",
    "            types.Part(\n",
    "                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=9hE5-98ZeCg')\n",
    "            ),\n",
    "            types.Part(text='Please summarize the video in 3 sentences.')\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# 결과 출력\n",
    "print(response)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
